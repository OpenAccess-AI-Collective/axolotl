{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c388a8-6d3d-41b4-b1e8-53ef499fba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --ignore-installed sentencepiece langchain huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4864926-836c-4ac2-a945-5a6851992723",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076b79c2-9147-4e26-915a-0f98199e355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig, LlamaForCausalLM, BitsAndBytesConfig, pipeline, TextStreamer, StoppingCriteria, StoppingCriteriaList, logging\n",
    "import textwrap\n",
    "import locale\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095aec3b-f34d-4466-af1c-7766b076c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/workspace/axolotl/src/out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77864c8-ec3e-4f78-a7f9-53a9d2bfa6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6cae43d97f4d40b954c17c22fbd303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "print(\"Model & tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff040e6-c568-4260-a6cd-4b310a39807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "stream_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=4096,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.15,\n",
    "    batch_size=8,\n",
    "    streamer=streamer,\n",
    ")\n",
    "stream_llm = HuggingFacePipeline(pipeline=stream_pipeline)\n",
    "stream_template = f'''{tokenizer.bos_token}<|system|>Act as an helpful assistant. Whenever a user poses a question or presents an issue, respond with clear, accurate, and comprehensive solutions or explanations tailored to address the query. Prioritize user clarity and the relevancy of your response.{tokenizer.eos_token}\n",
    "<|user|>user\\n'''\n",
    "stream_template += \"{query}\"\n",
    "stream_template += f'''{tokenizer.eos_token}<|assistant|>\\n'''\n",
    "\n",
    "stream_prompt = PromptTemplate(template=stream_template, input_variables=[\"query\"])\n",
    "stream_llm_chain = LLMChain(prompt=stream_prompt, llm=stream_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8627a74-121d-4227-8f69-4fc0012efbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To fetch data from the Google News API using Node.js, we will use the `request` library to make HTTP requests and `cheerio` to parse HTML content. If you don't have these libraries installed, you can install them using npm (Node Package Manager) by running:\n",
      "\n",
      "```bash\n",
      "npm install request cheerio\n",
      "```\n",
      "\n",
      "Here is the complete code solution for fetching Google News articles:\n",
      "\n",
      "```javascript\n",
      "// Import necessary modules\n",
      "var request = require('request'); // To make HTTP requests\n",
      "var cheerio = require('cheerio'); // To parse HTML content\n",
      "\n",
      "// Function to fetch news from Google News API\n",
      "function fetchGoogleNews(callback) {\n",
      "   // The URL for the Google News API\n",
      "   var url = 'https://news.google.com/rss';\n",
      "   \n",
      "   // Request options\n",
      "   var options = {\n",
      "       url: url,\n",
      "       headers: {\n",
      "           'User-Agent': 'Request-Headers' // Set the User-Agent to avoid being blocked\n",
      "       }\n",
      "   };\n",
      "   \n",
      "   // Make an HTTP GET request to the Google News API\n",
      "   request(options, function(error, response, body) {\n",
      "       if (!error && response.statusCode == 200) {\n",
      "           // Parse the HTML content using cheerio\n",
      "           var $ = cheerio.load(body);\n",
      "           \n",
      "           // Initialize an array to hold the news items\n",
      "           var newsItems = [];\n",
      "           \n",
      "           // Select all news items from the HTML\n",
      "           $('item').each(function() {\n",
      "               // Extract the title and description of each item\n",
      "               var title = $(this).find('title').text();\n",
      "               var description = $(this).find('description').text();\n",
      "               \n",
      "               // Create a new object to store the news item\n",
      "               var newsItem = {\n",
      "                   title: title,\n",
      "                   description: description\n",
      "               };\n",
      "               \n",
      "               // Add the new news item to the array\n",
      "               newsItems.push(newsItem);\n",
      "           });\n",
      "           \n",
      "           // Call the callback function with the parsed news items\n",
      "           callback(null, newsItems);\n",
      "       } else {\n",
      "           // Handle errors (e.g., network issues)\n",
      "           callback(error, null);\n",
      "       }\n",
      "   });\n",
      "}\n",
      "\n",
      "// Example usage of the fetchGoogleNews function\n",
      "fetchGoogleNews(function(err, newsItems) {\n",
      "   if (err) {\n",
      "       console.error(\"Error fetching news: \" + err);\n",
      "   } else {\n",
      "       // Output the news items\n",
      "       console.log(newsItems);\n",
      "   }\n",
      "});\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "\n",
      "1. **Import Modules**: We import the `request` module to make HTTP requests and the `cheerio` module to parse HTML content.\n",
      "\n",
      "2. **Function Definition**: The `fetchGoogleNews` function is defined to encapsulate the logic for fetching news. It takes a callback function as an argument.\n",
      "\n",
      "3. **URL and Options**: The URL for the Google News API is set and request options are defined, including a custom User-Agent to mimic a browser.\n",
      "\n",
      "4. **Making the Request**: Using the `request` module, an HTTP GET request is made to the Google News API.\n",
      "\n",
      "5. **Parsing the Response**: If the request is successful, the response body is passed to Cheerio for parsing.\n",
      "\n",
      "6. **Selecting News Items**: We use Cheerio to select all `<item>` elements, which contain individual news items.\n",
      "\n",
      "7. **Extracting Data**: For each selected `<item>`, we extract the `title` and `description`. These are then stored in a JSON object called `newsItem`.\n",
      "\n",
      "8. **Storing Results**: Each `newsItem` is pushed into a larger array called `newsItems`, which stores all the extracted news items.\n",
      "\n",
      "9. **Callback**: Once all news items have been processed, the callback function is called with two arguments: `null` for the error (since there was no error), and the array of `newsItems` for the result.\n",
      "\n",
      "10. **Example Usage**: An example is provided to demonstrate how to call the `fetchGoogleNews` function and handle the results.\n",
      "\n",
      "### Error Handling:\n",
      "\n",
      "The code includes basic error handling by checking the status code of the response and passing any errors to the callback. In a production environment, you would want to be more robust, possibly retrying requests or handling specific error codes differently.\n",
      "\n",
      "### Output:\n",
      "\n",
      "When running the example usage, the output will be an array of news items printed to the console. The actual output will depend on the current state of the Google News API at the time of execution.\n",
      "\n",
      "```output\n",
      "[\n",
      " { title: 'Article Title 1', description: 'A brief description of Article 1.' },\n",
      " { title: 'Article Title 2', description: 'A brief description of Article 2.' },\n",
      " // ... up to 10 articles depending on the API response\n",
      "]\n",
      "```\n",
      "\n",
      "This code provides a simple yet effective way to fetch news from the Google News API using Node.js. It can be extended further by adding additional features such as pagination, filtering, and handling different types of news categories.</s>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To fetch data from the Google News API using Node.js, we will use the `request` library to make HTTP requests and `cheerio` to parse HTML content. If you don\\'t have these libraries installed, you can install them using npm (Node Package Manager) by running:\\n\\n```bash\\nnpm install request cheerio\\n```\\n\\nHere is the complete code solution for fetching Google News articles:\\n\\n```javascript\\n// Import necessary modules\\nvar request = require(\\'request\\'); // To make HTTP requests\\nvar cheerio = require(\\'cheerio\\'); // To parse HTML content\\n\\n// Function to fetch news from Google News API\\nfunction fetchGoogleNews(callback) {\\n    // The URL for the Google News API\\n    var url = \\'https://news.google.com/rss\\';\\n    \\n    // Request options\\n    var options = {\\n        url: url,\\n        headers: {\\n            \\'User-Agent\\': \\'Request-Headers\\' // Set the User-Agent to avoid being blocked\\n        }\\n    };\\n    \\n    // Make an HTTP GET request to the Google News API\\n    request(options, function(error, response, body) {\\n        if (!error && response.statusCode == 200) {\\n            // Parse the HTML content using cheerio\\n            var $ = cheerio.load(body);\\n            \\n            // Initialize an array to hold the news items\\n            var newsItems = [];\\n            \\n            // Select all news items from the HTML\\n            $(\\'item\\').each(function() {\\n                // Extract the title and description of each item\\n                var title = $(this).find(\\'title\\').text();\\n                var description = $(this).find(\\'description\\').text();\\n                \\n                // Create a new object to store the news item\\n                var newsItem = {\\n                    title: title,\\n                    description: description\\n                };\\n                \\n                // Add the new news item to the array\\n                newsItems.push(newsItem);\\n            });\\n            \\n            // Call the callback function with the parsed news items\\n            callback(null, newsItems);\\n        } else {\\n            // Handle errors (e.g., network issues)\\n            callback(error, null);\\n        }\\n    });\\n}\\n\\n// Example usage of the fetchGoogleNews function\\nfetchGoogleNews(function(err, newsItems) {\\n    if (err) {\\n        console.error(\"Error fetching news: \" + err);\\n    } else {\\n        // Output the news items\\n        console.log(newsItems);\\n    }\\n});\\n```\\n\\n### Explanation of the Code:\\n\\n1. **Import Modules**: We import the `request` module to make HTTP requests and the `cheerio` module to parse HTML content.\\n\\n2. **Function Definition**: The `fetchGoogleNews` function is defined to encapsulate the logic for fetching news. It takes a callback function as an argument.\\n\\n3. **URL and Options**: The URL for the Google News API is set and request options are defined, including a custom User-Agent to mimic a browser.\\n\\n4. **Making the Request**: Using the `request` module, an HTTP GET request is made to the Google News API.\\n\\n5. **Parsing the Response**: If the request is successful, the response body is passed to Cheerio for parsing.\\n\\n6. **Selecting News Items**: We use Cheerio to select all `<item>` elements, which contain individual news items.\\n\\n7. **Extracting Data**: For each selected `<item>`, we extract the `title` and `description`. These are then stored in a JSON object called `newsItem`.\\n\\n8. **Storing Results**: Each `newsItem` is pushed into a larger array called `newsItems`, which stores all the extracted news items.\\n\\n9. **Callback**: Once all news items have been processed, the callback function is called with two arguments: `null` for the error (since there was no error), and the array of `newsItems` for the result.\\n\\n10. **Example Usage**: An example is provided to demonstrate how to call the `fetchGoogleNews` function and handle the results.\\n\\n### Error Handling:\\n\\nThe code includes basic error handling by checking the status code of the response and passing any errors to the callback. In a production environment, you would want to be more robust, possibly retrying requests or handling specific error codes differently.\\n\\n### Output:\\n\\nWhen running the example usage, the output will be an array of news items printed to the console. The actual output will depend on the current state of the Google News API at the time of execution.\\n\\n```output\\n[\\n  { title: \\'Article Title 1\\', description: \\'A brief description of Article 1.\\' },\\n  { title: \\'Article Title 2\\', description: \\'A brief description of Article 2.\\' },\\n  //... up to 10 articles depending on the API response\\n]\\n```\\n\\nThis code provides a simple yet effective way to fetch news from the Google News API using Node.js. It can be extended further by adding additional features such as pagination, filtering, and handling different types of news categories.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_llm_chain.run('''Write code fetch google news api using nodejs.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6f770-a96f-450b-9af6-f998d1f2c21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
