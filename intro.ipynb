{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"true\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from axolotl.utils.dict import DictDefault\n",
    "from axolotl.cli.train import do_train\n",
    "from axolotl.common.cli import TrainerCliArgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Basic configuration for\n",
    "cfg = DictDefault({\n",
    "    \"base_model\": \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n",
    "    \"model_kwargs\": {\"from_tf\": True},\n",
    "    \"load_in_4bit\": True,\n",
    "    \"datasets\": [{\"path\": \"mhenrichsen/alpaca_2k_test\", \"type\": \"alpaca\"}],\n",
    "    \"val_set_size\": 0.1,\n",
    "    \"output_dir\": \"./lora-out\",\n",
    "    \"sequence_len\": 2048,\n",
    "    \"sample_packing\": True,\n",
    "    \"pad_to_sequence_len\": True,\n",
    "    \"adapter\": \"qlora\",\n",
    "    \"lora_r\": 32,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"lora_target_linear\": True,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"micro_batch_size\": 1,\n",
    "    \"eval_batch_size\": 1,\n",
    "    \"num_epochs\": 1,\n",
    "    \"optimizer\": \"adamw_bnb_8bit\",\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"bf16\": \"auto\",\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"logging_steps\": 1,\n",
    "    \"flash_attention\": True,\n",
    "    \"warmup_steps\": 10,\n",
    "    \"evals_per_epoch\": 4,\n",
    "    \"saves_per_epoch\": 1,\n",
    "    \"weight_decay\": 0.0,\n",
    "})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kick off the training\n",
    "model, tokenizer = do_train(cfg, TrainerCliArgs())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
